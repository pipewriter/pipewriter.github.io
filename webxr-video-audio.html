<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>WebXR Inside Sphere with Floating Image and Topo Map</title>
  <style>
    body { margin: 0; overflow: hidden; }
    canvas { display: block; }
  </style>
</head>
<body>
<script type="module">
import * as THREE from 'https://unpkg.com/three@0.153.0/build/three.module.js';
import { VRButton } from 'https://unpkg.com/three@0.153.0/examples/jsm/webxr/VRButton.js';

let scene, camera, renderer, sphere;
const clock = new THREE.Clock();

init();
animate();

function init() {
  // Scene & Camera
  scene = new THREE.Scene();
  camera = new THREE.PerspectiveCamera(70, window.innerWidth / window.innerHeight, 0.1, 100);
  camera.position.set(0, 0, 0);

  // Renderer & XR setup
  renderer = new THREE.WebGLRenderer({ antialias: true });
  renderer.setPixelRatio(window.devicePixelRatio);
  renderer.setSize(window.innerWidth, window.innerHeight);
  renderer.xr.enabled = true;
  document.body.appendChild(renderer.domElement);
  document.body.appendChild(VRButton.createButton(renderer));

  // ─── Three.js Audio Setup ───────────────────────────────────────────────
  // 1. Attach an AudioListener to the camera
  const listener = new THREE.AudioListener();
  camera.add(listener);

  // 2. Create the Three.js Audio source and preload your song
  const sound = new THREE.Audio(listener);
  const audioLoader = new THREE.AudioLoader();
  audioLoader.load(
    'song.mp3',                       // your song file
    buffer => {
      sound.setBuffer(buffer);
      sound.setLoop(true);
      sound.setVolume(0.5);
    },
    xhr => console.log(`Audio ${(xhr.loaded/xhr.total*100).toFixed(1)}% loaded`),
    err => console.error('Audio load error:', err)
  );

  // 3. When the XR session actually starts (i.e. user clicked “Enter VR”), resume the AudioContext and play
  renderer.xr.addEventListener('sessionstart', async () => {
    try {
      // In many browsers the AudioContext is suspended until a user gesture
      await sound.context.resume();
    } catch(e) {
      console.warn('AudioContext resume failed:', e);
    }
    if (!sound.isPlaying) sound.play();
  });

  // (Optional) stop the music when they exit VR:
  renderer.xr.addEventListener('sessionend', () => {
    if (sound.isPlaying) sound.stop();
  });
  // ────────────────────────────────────────────────────────────────────────


  // Inverted Lava Lamp Sphere
  const sphereGeo = new THREE.SphereGeometry(5, 64, 64);
  const sphereUniforms = { time: { value: 0.0 } };
  const sphereMat = new THREE.ShaderMaterial({
    uniforms: sphereUniforms,
    vertexShader: `
      varying vec2 vUv;
      void main() {
        vUv = uv;
        gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
      }
    `,
    fragmentShader: `
      // 2D Simplex Noise
      vec3 mod289(vec3 x){return x - floor(x * (1.0 / 289.0)) * 289.0;}
      vec2 mod289(vec2 x){return x - floor(x * (1.0 / 289.0)) * 289.0;}
      vec3 permute(vec3 x){return mod289(((x*34.0)+1.0)*x);}
      float snoise(vec2 v) {
        const vec4 C = vec4(0.2113248654,0.3660254038,-0.5773502692,0.0243902439);
        vec2 i = floor(v + dot(v, C.yy));
        vec2 x0 = v - i + dot(i, C.xx);
        vec2 i1 = x0.x> x0.y? vec2(1.0,0.0): vec2(0.0,1.0);
        vec4 x12 = x0.xyxy + C.xxzz;
        x12.xy -= i1;
        i = mod289(i);
        vec3 p = permute(permute(i.y + vec3(0.0, i1.y, 1.0)) + i.x + vec3(0.0, i1.x, 1.0));
        vec3 m = max(0.5 - vec3(dot(x0,x0), dot(x12.xy,x12.xy), dot(x12.zw,x12.zw)), 0.0);
        m = m*m*m*m;
        vec3 x = 2.0 * fract(p * C.www) - 1.0;
        vec3 h = abs(x) - 0.5;
        vec3 ox = floor(x + 0.5);
        vec3 a0 = x - ox;
        m *= 1.79284291400159 - 0.85373472095314 * (a0*a0 + h*h);
        vec3 g;
        g.x = a0.x * x0.x + h.x * x0.y;
        g.yz = a0.yz * x12.xz + h.yz * x12.yw;
        return 130.0 * dot(m, g);
      }
      varying vec2 vUv;
      uniform float time;
      void main() {
        vec2 uv = vUv * 2.0 - 1.0;
        float speed = 0.8;
        float rotSpeed = 0.2;
        float angle = time * rotSpeed;
        mat2 rot = mat2(cos(angle), -sin(angle), sin(angle), cos(angle));
        vec2 p = rot * uv;
        p.y += time * speed;
        p.y = mod(p.y + 2.0, 4.0) - 2.0;
        float swirl = snoise(vec2(p.y * 0.3, time * 0.4));
        p.x += swirl * 0.5;
        float n1 = snoise(p * 1.5);
        float n2 = snoise((p + vec2(6.0,-4.0)) * 2.5);
        float blob = smoothstep(0.25, 0.6, n1 + n2 * 0.6);
        vec3 col = mix(vec3(0.2,0.0,0.0), vec3(1.0,0.8,0.1), blob);
        gl_FragColor = vec4(col,1.0);
      }
    `,
    side: THREE.BackSide
  });
  sphere = new THREE.Mesh(sphereGeo, sphereMat);
  scene.add(sphere);

  // Create a pivot on the camera for UI elements
  const uiPivot = new THREE.Object3D();
  uiPivot.position.set(0, 0, 0);
  camera.add(uiPivot);
  scene.add(camera);

  // Floating Image Quad
  const loader = new THREE.TextureLoader();
  const imgUrl = 'profile_pic.jpg'; // replace with your image path or data URI
  loader.load(imgUrl, texture => {
    const aspect = texture.image.width / texture.image.height;
    const quadGeo = new THREE.PlaneGeometry(1.0 * aspect, 1.0);
    const quadMat = new THREE.MeshBasicMaterial({ map: texture, transparent: true });
    const quad = new THREE.Mesh(quadGeo, quadMat);
    quad.position.set(0.8, -0.3, -1.2);
    uiPivot.add(quad);
  });

  // Floating Topo Map
  const mapSegments = 64;
  const mapSize = 1.2;
  const terrainGeo = new THREE.PlaneGeometry(mapSize, mapSize, mapSegments, mapSegments);
  // Shader for terrain: displacement + color by height
  const terrainMat = new THREE.ShaderMaterial({
    vertexShader: `
      varying float vHeight;
      varying vec2 vUv;
      // 2D Simplex Noise (same as above)
      vec3 mod289(vec3 x){return x - floor(x*(1.0/289.0))*289.0;}
      vec2 mod289(vec2 x){return x - floor(x*(1.0/289.0))*289.0;}
      vec3 permute(vec3 x){return mod289(((x*34.0)+1.0)*x);}      
      float snoise(vec2 v){
        const vec4 C = vec4(0.2113248654,0.3660254038,-0.5773502692,0.0243902439);
        vec2 i=floor(v+dot(v,C.yy));
        vec2 x0=v-i+dot(i,C.xx);
        vec2 i1=x0.x>x0.y?vec2(1.0,0.0):vec2(0.0,1.0);
        vec4 x12=x0.xyxy+C.xxzz; x12.xy-=i1;
        i=mod289(i);
        vec3 p=permute(permute(i.y+vec3(0.0,i1.y,1.0))+i.x+vec3(0.0,i1.x,1.0));
        vec3 m=max(0.5-vec3(dot(x0,x0),dot(x12.xy,x12.xy),dot(x12.zw,x12.zw)),0.0);
        m=m*m*m*m;
        vec3 x=2.0*fract(p*C.www)-1.0;
        vec3 h=abs(x)-0.5;
        vec3 ox=floor(x+0.5);
        vec3 a0=x-ox;
        m*=1.79284291400159-0.85373472095314*(a0*a0+h*h);
        vec3 g; g.x=a0.x*x0.x+h.x*x0.y;
        g.yz=a0.yz*x12.xz+h.yz*x12.yw;
        return 130.0*dot(m,g);
      }
      uniform float time;
      void main(){
        vUv = uv;
        // Displace along normal
        float scale = 3.0;
        float amp = 0.3;
        vec2 p = uv * scale;
        float h = snoise(p);
        vHeight = h;
        vec3 displaced = position + normal * h * amp;
        gl_Position = projectionMatrix * modelViewMatrix * vec4(displaced,1.0);
      }
    `,
    fragmentShader: `
      varying float vHeight;
      varying vec2 vUv;
      void main() {
        // Color ramp by height
        vec3 color;
        if(vHeight < -0.1) color = vec3(0.0,0.2,0.6);      // water
        else if(vHeight < 0.0) color = mix(vec3(0.0,0.2,0.6), vec3(0.1,0.5,0.1), smoothstep(-0.1,0.0,vHeight));
        else if(vHeight < 0.2) color = mix(vec3(0.1,0.5,0.1), vec3(0.5,0.4,0.2), smoothstep(0.0,0.2,vHeight));
        else color = mix(vec3(0.5,0.4,0.2), vec3(1.0,1.0,1.0), smoothstep(0.2,0.5,vHeight));
        gl_FragColor = vec4(color,1.0);
      }
    `,
    side: THREE.DoubleSide
  });
  const terrain = new THREE.Mesh(terrainGeo, terrainMat);
  terrain.rotation.x = -Math.PI/2;
  terrain.position.set(2.0, -0.5, -1.2);
  uiPivot.add(terrain);


  // ─────────── Floating Video Quad ───────────
  // 1. create & hide a DOM video
  const video = document.createElement('video');
  video.src = 'trailer.webm';           // your video file
  video.loop = true;
  video.muted = true;
  video.playsInline = true;
  video.crossOrigin = 'anonymous';
  video.style.display = 'none';
  document.body.appendChild(video);

  // 2. attempt autoplay; on failure wait for a user gesture
  video.play().catch(() =>
    window.addEventListener('click', () => video.play())
  );

  // 3. make a VideoTexture once the first frame is ready
  video.addEventListener('loadeddata', () => {
    const videoTex = new THREE.VideoTexture(video);
    // 16:9 aspect scaled to ~1.6 × 0.9 units
    const vidGeo = new THREE.PlaneGeometry(1.6, 0.9);
    const vidMat = new THREE.MeshBasicMaterial({ map: videoTex });
    const vidMesh = new THREE.Mesh(vidGeo, vidMat);

    // position it next to your other UI quads
    vidMesh.position.set(-0.8, -0.3, -1.2);

    uiPivot.add(vidMesh);
  });
  // ─────────────────────────────────────────────

  window.addEventListener('resize', onWindowResize);
}

function onWindowResize() {
  camera.aspect = window.innerWidth / window.innerHeight;
  camera.updateProjectionMatrix();
  renderer.setSize(window.innerWidth, window.innerHeight);
}

function animate() {
  sphere.material.uniforms.time.value = clock.getElapsedTime();
  renderer.setAnimationLoop(render);
}

function render() {
  renderer.render(scene, camera);
}
</script>
</body>
</html>

